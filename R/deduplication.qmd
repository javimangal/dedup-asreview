---
title: "Deduplication of bibliographic records with ASySD in R"
date: today
execute: 
  echo: true
  warning: false
fig-cap-location: top
format:
  html:
    toc: true
    toc-depth: 1
    embed-resources: true
  docx:
    toc: false
    link-citations: true
  pdf:
    toc: false
    documentclass: scrartcl
editor: visual
---

This is a quarto document that contains both human language and R code. It works almost exactly as an R markdown file (.Rmd). [click here for more info](https://quarto.org/docs/get-started/hello/rstudio.html).

The structure of this R project is the same as the Utrecht University (UU) [simple R project](https://github.com/UtrechtUniversity/simple-r-project).

```{r}
#| label: directories
#| include: false

# Create directories for sub-folders  
inputfolder <- "../data/raw" # Raw data files that should not be modified.    
psfolder <- "../data/processed" # Machine-processed output files.
tempfolder <- "../data/temp" # Temporary files that can be deleted after processing.

dir.create(inputfolder, showWarnings = FALSE)
dir.create(psfolder, showWarnings = FALSE)
dir.create(tempfolder, showWarnings = FALSE)
```

```{r}
#| label: packages
#| include: false 

# Load packages with the pacman package. 
if (!require("pacman", quietly = TRUE)) {
  install.packages("pacman")
}

pacman::p_load(
  devtools,         # Used to install packages from GitHub.
  tidyverse,        # Used for basic data handling and visualization.
  overviewR,        # Used to check missing data.
  gt,               # Used to print html tables.  
  report            # Used to cite packages used in this session.   
)

# ASySD is not yet on CRAN, so we install it from GitHub. 
pacman::p_load_gh("camaradesuk/ASySD")  

```

# RIS files

For this deduplication challenges, all files are made available as Research Information Systems Incorporated (RIS) files, which can be read by the `load_search` function from the `ASySD` package. The RIS files are available in the `data/raw` folder. The four datasets to be deduplicated were presumably obtained from the following databases:

-   **Embase**
-   **Lens**
-   **OpenAlex**
-   **Scopus**

We will use ASySD to load the datasets by using the `load_search` function for a RIS file.

In order to run these analysis, make sure that your data files are already inside the `data/raw` folder. 

#### Embase

```{r}
#| label: embase load

# Load embase data 
embase_raw <- load_search(
  path = paste0(inputfolder, "/5_ASReviewSummSchool_Embase.ris"),
  method = "ris"
  )

# Examine the names of the loaded dataset 
embase_raw %>% names
```

There are a total of `r count(embase_raw)` records in the embase dataset.

Since ASySD expects the data to have a rather strict structure, further processing is necessary. The columns that ASySD expects are:

| **Name** | **Definition** |
|------------------|------------------------------------------------------|
| **author** | The author(s) of the publication |
| **year** | The year the publication was published |
| **journal** | The name of the journal in which the publication appeared |
| **doi** | The Digital Object Identifier (DOI) assigned to the publication |
| **title** | The title of the publication |
| **pages** | The page numbers of the publication |
| **volume** | The volume number of the publication (if applicable) |
| **number** | The issue number of the publication (if applicable) |
| **abstract** | Abstract of publication |
| **record_id** | A unique identifier for the publication. If this is not obtained from the citation file, ASySD will genereate an id for each citation based on row numbers. |
| **isbn** | The International Standard Book Number (ISBN) assigned to the publication (if applicable). If unavailable, the International Standard Serial Number can be used here instead (ISSN). |
| **label (optional)** | A label or tag assigned to the publication (if applicable) - for example, **new search** or **old search** |
| **source (optional)** | The source or database from which the publication was obtained - for example **wos**, **embase**, **pubmed**, **scopus** |

> This table was extracted and exactly reproduced from [ASySD GitHub site](https://github.com/camaradesuk/ASySD).

We thus need to select the columns that ASySD expects and rename them accordingly.

```{r}
# Columns to select 
columns <- c("record_id", "author", "year", "journal", "doi", "title", "pages",
             "volume", "number", "abstract", "isbn", "label", "source")
```

```{r}
#| label: embase processing

embase <- embase_raw %>% 
  mutate(
    record_id = record_id, # None available in this dataset, 
                           # empty column created by load_search 
    author = author,     # Correct, pattern = "Last, F. S. and" 
    year = year,         # Correct
    journal = journal,   # Correct 
    doi = doi,           # Correct 
    title = title,       # Correct 
    pages = pages,       # Correct, note separated by "-" with no spaces.
    volume = volume,     # Correct
    number = issue,      # Called issue in original dataset
    abstract = abstract, # Correct     
    isbn = issn,         # Called issn in original dataset, may have >1 separated 
                         # by " and " with spaces.
    label = label,       # Empty column created by load_search
    source = database    # Called database in original dataset
    ) %>% 
  select(all_of(columns)) %>% 
  mutate_if(is.character, ~na_if(., "")) # Replace empty strings with NA
    
```

#### Scopus

```{r}
#| label: scopus load

# Load scopus data 
scopus_raw <- load_search(
  path = paste0(inputfolder, "/25_ASreviewSummSchool_Scopus.ris"),
  method = "ris"
  )

# Examine the names of the loaded dataset 
scopus_raw %>% names
```

There are a total of `r count(scopus_raw)` records in the scopus dataset.

```{r}
#| label: scopus processing

scopus <- scopus_raw %>% 
  mutate(
    record_id = record_id, # None available in this dataset, 
                           # empty column created by load_search 
    author = author,      # Correct, pattern = "Last, F. S. and" 
    year = year,          # Correct
    journal = journal,    # Correct 
    doi = doi,            # Correct 
    title = title,        # Correct 
    pages = pages,        # Correct, note separated by "-" with no spaces.
    volume = volume,      # Correct
    number = issue,       # Called issue in original dataset
    abstract = abstract,  # Correct     
    isbn = issn,          # Called issn in original dataset with 
                          # "(ISSN)" or "(ISBN)" sting after, 
                          # may have >1 separated by ";"
    label = label,        # Empty column created by load_search
    source = database     # Called database in original dataset
    ) %>% 
  select(all_of(columns)) %>% 
  mutate_if(is.character, ~na_if(., "")) # Replace empty strings with NA
    
```

#### OpenAlex

```{r}
#| label: openalex load 

# Load openalex data 
openalex_raw <- load_search(
  path = paste0(inputfolder, "/2658_ASReviewSummerschool_OpenAlex.ris"),
  method = "ris"
  )

# Examine the names of the loaded dataset 
openalex_raw %>% names
```

There are a total of `r count(openalex_raw)` records in the openalex dataset.

```{r}
#| label: openalex processing

openalex <- openalex_raw %>% 
  mutate(
    record_id = record_id, # None available in this dataset, 
                           # empty column created by load_search 
    author = author,      # Correct, pattern = "Last, First and" 
    year = year,          # Correct
    journal = journal,    # Correct 
    doi = doi,            # Correct 
    title = title,        # Correct 
    pages = pages,        # Correct, note separated by "-" with no spaces.
    volume = volume,      # Correct
    number = issue,       # Called issue in original dataset
    abstract = abstract,  # Correct     
    isbn = issn,          # Called issn in original dataset, single issn.
    label = label,        # Empty column created by load_search
    source = "openalex"   # Not available, will call it openalex
    ) %>% 
  select(all_of(columns)) %>% 
  mutate_if(is.character, ~na_if(., "")) # Replace empty strings with NA
    
```

#### Lens

```{r}
#| label: lens load 

# Load lens data 
lens_raw <- load_search(
  path = paste0(inputfolder, "/568-ASReviewSummerschool-LENS.ris"),
  method = "ris"
  )

# Examine the names of the loaded dataset 
lens_raw %>% names
```

There are a total of `r count(lens_raw)` records in the lens dataset.

```{r}
#| label: lens processing

lens <- lens_raw %>% 
  mutate(
    record_id = record_id, # None available in this dataset, 
                           # empty column created by load_search 
    author = author,      # Correct, pattern = "Last, First and" 
    year = year,          # Correct
    journal = journal,    # Correct 
    doi = doi,            # Correct 
    title = title,        # Correct
    pages = pages,        # Correct, note separated by "-" with no spaces.
    volume = volume,      # Correct
    number = issue,       # Called issue in original dataset
    abstract = abstract,  # Correct, but html code is present.      
    isbn = issn,          # Called issn in original dataset, 
                          # may have >1 separated by " and " with spaces.
    label = label,        # Empty column created by load_search
    source = "lens"       # Not available, will call it lens
    ) %>% 
  select(all_of(columns)) %>% 
  mutate_if(is.character, ~na_if(., "")) # Replace empty strings with NA
    
```

# Examine missing data

```{r}
#| label: missing
#| fig-cap: "**Figure 1**. Missing data per database"
#| fig-subcap:
#|   - "Embase"
#|   - "Scopus"
#|   - "OpenAlex"
#|   - "Lens"
#| layout-ncol: 2

overview_na(embase)
overview_na(scopus)
overview_na(openalex)
overview_na(lens)
```

```{r}
#| label: merge
#| 
# Bind all datasets 
records <- bind_rows(
  embase,
  scopus,
  openalex,
  lens
  )

```

There are a total of `r count(records)` records. These will be deduplicated using the Automated Systematic Search Deduplicator (ASySD).

```{r}
#| label: deduplication

# Deduplicate studies
deduplicated <- dedup_citations(
  records, 
  manual_dedup =  TRUE,
  show_unknown_tags = FALSE,
  user_input = 1
  )

# If only journal articles, removing doi exact matches could be appropriate
# this will remove many manual duplicates already, useful for large datasets.
records_unique <- deduplicated$unique 
record_manual_dedup <- deduplicated$manual_dedup %>% 
  mutate(
    result = case_when(
      doi >0.9999 ~ TRUE, 
      TRUE ~ NA
    )
  )
```

```{r}
#| label: shiny
#| eval: false # set to false only for rendering purposes

# This will open a Shiny app to manually deduplicate the records.
true_dups <- manual_dedup_shiny(record_manual_dedup)

# Saved as a temporary file to prevent any progress lost.
saveRDS(true_dups, file = paste0(tempfolder, "/true_duplicates.rds"))
```

```{r}
# Reload the true duplicates from the temporary file.
true_dups <- readRDS(paste0(tempfolder, "/true_duplicates.rds")) 

# Incorporate manual decisions into the final dataset. 
final_dedup <- dedup_citations_add_manual(records_unique, additional_pairs = true_dups)
```

```{r}
#| label: save final

write_citations(
  final_dedup,
  type = "csv",
  filename = paste0(psfolder, "/deduplicated_final.csv")
  )
```

# Final thoughts 

After deduplication, there were a total of `r count(final_dedup)` studies. Thus, the final number of duplicated records was: `r count(records) - count(final_dedup)`.

However, the data had remaining unfixed issues such as different name patterns and issn, so it would be good to examine if fixing this changes the results.

Overall, ASySD is quite useful but may require quite a lot of coding and data preparation to get reliable results. 

{{< pagebreak >}}

# Session Information

```{r}
#| label: session
# remove clutter
session <- sessionInfo()
session$BLAS <- NULL
session$LAPACK <- NULL
session$loadedOnly <- NULL

session
```

{{< pagebreak >}}

# Package References

```{r}
#| output: asis
report::cite_packages(session)
```

```{r}
#| include: false

# Run this chunk if you wish to clear your environment and unload packages.

pacman::p_unload(negate = TRUE)

rm(list = ls())
```
